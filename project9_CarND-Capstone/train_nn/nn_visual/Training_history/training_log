1. 

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
vgg16 (Model)                multiple                  14714688  
_________________________________________________________________
flatten_1 (Flatten)          (None, 12800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 51204     
=================================================================
Total params: 14,765,892
Trainable params: 14,765,892
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/1
 2/23 [=>............................] - ETA: 2296s - loss: 31.7126 - acc: 0.218 3/23 [==>...........................] - ETA: 2231s - loss: 21.2105 - acc: 0.281 4/23 [====>.........................] - ETA: 2144s - loss: 16.3809 - acc: 0.250 5/23 [=====>........................] - ETA: 2085s - loss: 15.1926 - acc: 0.231 6/23 [======>.......................] - ETA: 1998s - loss: 26.2556 - acc: 0.244 7/23 [========>.....................] - ETA: 1876s - loss: 22.5471 - acc: 0.245 8/23 [=========>....................] - ETA: 1750s - loss: 19.7550 - acc: 0.265 9/23 [==========>...................] - ETA: 1636s - loss: 17.5832 - acc: 0.26310/23 [============>.................] - ETA: 1515s - loss: 15.8454 - acc: 0.25011/23 [=============>................] - ETA: 1418s - loss: 14.4275 - acc: 0.25212/23 [==============>...............] - ETA: 1305s - loss: 13.2422 - acc: 0.26013/23 [===============>..............] - ETA: 1196s - loss: 12.2439 - acc: 0.25014/23 [=================>............] - ETA: 1066s - loss: 11.3900 - acc: 0.25015/23 [==================>...........] - ETA: 941s - loss: 10.6424 - acc: 0.258323/23 [==============================] - 2927s - loss: 7.0085 - acc: 0.2677 - val_loss: 0.1713 - val_acc: 0.4188
Model saved successfully

2.

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
vgg16 (Model)                multiple                  14714688  
_________________________________________________________________
flatten_1 (Flatten)          (None, 12800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 51204     
=================================================================
Total params: 14,765,892
Trainable params: 14,765,892
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/5
 2/23 [=>............................] - ETA: 1018s - loss: 112468072.4636 - acc 3/23 [==>...........................] - ETA: 939s - loss: 74978715.2144 - acc:  4/23 [====>.........................] - ETA: 887s - loss: 56234036.6623 - acc:  5/23 [=====>........................] - ETA: 826s - loss: 44987267.9630 - acc:  6/23 [======>.......................] - ETA: 770s - loss: 37489425.3403 - acc:  7/23 [========>.....................] - ETA: 718s - loss: 32133840.4042 - acc:  8/23 [=========>....................] - ETA: 671s - loss: 28119060.7444 - acc:  9/23 [==========>...................] - ETA: 627s - loss: 24995990.0720 - acc: 10/23 [============>.................] - ETA: 585s - loss: 22506235.2952 - acc: 11/23 [=============>................] - ETA: 540s - loss: 20465476.8607 - acc: 12/23 [==============>...............] - ETA: 494s - loss: 18761778.8310 - acc: 13/23 [===============>..............] - ETA: 448s - loss: 17318602.4014 - acc: 14/23 [=================>............] - ETA: 403s - loss: 16081571.1719 - acc: 15/23 [==================>...........] - ETA: 358s - loss: 15009512.7305 - acc: 16/23 [===================>..........] - ETA: 312s - loss: 14071437.3132 - acc: 17/23 [=====================>........] - ETA: 267s - loss: 13243706.6753 - acc: 18/23 [======================>.......] - ETA: 222s - loss: 12507945.8649 - acc: 19/23 [=======================>......] - ETA: 178s - loss: 11849633.1343 - acc: 20/23 [=========================>....] - ETA: 133s - loss: 11257151.5312 - acc: 21/23 [==========================>...] - ETA: 88s - loss: 10721096.7263 - acc: 022/23 [===========================>..] - ETA: 44s - loss: 10233774.1625 - acc: 023/23 [==============================] - 1095s - loss: 9788827.4702 - acc: 0.3152 - val_loss: 0.2549 - val_acc: 0.2250
Epoch 2/5
23/23 [==============================] - 1050s - loss: 0.2197 - acc: 0.2640 - val_loss: 0.1940 - val_acc: 0.3312
Epoch 3/5
23/23 [==============================] - 1056s - loss: 0.1959 - acc: 0.3518 - val_loss: 0.1831 - val_acc: 0.3500
Epoch 4/5
23/23 [==============================] - 1450s - loss: 0.1816 - acc: 0.3821 - val_loss: 0.1723 - val_acc: 0.3567
Epoch 5/5
23/23 [==============================] - 1063s - loss: 0.1865 - acc: 0.3508 - val_loss: 0.1753 - val_acc: 0.3438
Model saved successfully

3,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 158, 158, 32)      896       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 79, 79, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 77, 77, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 38, 38, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 38, 38, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 92416)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 369668    
=================================================================
Total params: 389,060
Trainable params: 389,060
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/5
2020-01-29 00:16:17.383259: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:16:17.383301: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:16:17.383314: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:16:17.383326: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
13/13 [==============================] - 27s - loss: 4.5253 - acc: 0.2596 - val_loss: 0.2238 - val_acc: 0.2292
Epoch 2/5
13/13 [==============================] - 24s - loss: 0.1932 - acc: 0.4016 - val_loss: 0.1699 - val_acc: 0.4667
Epoch 3/5
13/13 [==============================] - 24s - loss: 0.1463 - acc: 0.6353 - val_loss: 0.1538 - val_acc: 0.5733
Epoch 4/5
13/13 [==============================] - 23s - loss: 0.1037 - acc: 0.7924 - val_loss: 0.1082 - val_acc: 0.7200
Epoch 5/5
13/13 [==============================] - 25s - loss: 0.0746 - acc: 0.8431 - val_loss: 0.1025 - val_acc: 0.7708
Model saved successfully
student@udacity:~/CarND-Capstone/train_nn$ python train.py
Using TensorFlow backend.

4,

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 158, 158, 16)      448       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 79, 79, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 77, 77, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 38, 38, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 36, 36, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 18, 18, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 20736)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 82948     
=================================================================
Total params: 106,532
Trainable params: 106,532
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/5
2020-01-29 00:20:02.387018: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:20:02.387084: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:20:02.387100: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:20:02.387111: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
13/13 [==============================] - 18s - loss: 0.4235 - acc: 0.3005 - val_loss: 0.2191 - val_acc: 0.2812
Epoch 2/5
13/13 [==============================] - 17s - loss: 0.1921 - acc: 0.2956 - val_loss: 0.1755 - val_acc: 0.4933
Epoch 3/5
13/13 [==============================] - 16s - loss: 0.1717 - acc: 0.4793 - val_loss: 0.1717 - val_acc: 0.5067
Epoch 4/5
13/13 [==============================] - 16s - loss: 0.1428 - acc: 0.6934 - val_loss: 0.1440 - val_acc: 0.6667
Epoch 5/5
13/13 [==============================] - 15s - loss: 0.1155 - acc: 0.7634 - val_loss: 0.1274 - val_acc: 0.6533
Model saved successfully

5,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 158, 158, 16)      448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 158, 158, 16)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 156, 156, 32)      4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 78, 78, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 76, 76, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 38, 38, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 38, 38, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 92416)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 369668    
=================================================================
Total params: 393,252
Trainable params: 393,252
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/5
2020-01-29 00:23:35.797120: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:23:35.797226: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:23:35.797277: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 00:23:35.797325: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
13/13 [==============================] - 44s - loss: 6.8330 - acc: 0.2380 - val_loss: 0.2123 - val_acc: 0.1771
Epoch 2/5
13/13 [==============================] - 38s - loss: 0.2065 - acc: 0.2118 - val_loss: 0.2060 - val_acc: 0.2933
Epoch 3/5
13/13 [==============================] - 39s - loss: 0.1898 - acc: 0.3632 - val_loss: 0.1972 - val_acc: 0.3333
Epoch 4/5
13/13 [==============================] - 39s - loss: 0.1841 - acc: 0.3430 - val_loss: 0.1892 - val_acc: 0.3867
Epoch 5/5
13/13 [==============================] - 42s - loss: 0.1798 - acc: 0.4108 - val_loss: 0.1840 - val_acc: 0.4933

6.

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 158, 158, 16)      448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 158, 158, 16)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 399424)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1597700   
=================================================================
Total params: 1,598,148
Trainable params: 1,598,148
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/10
2020-01-29 15:39:48.443759: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 15:39:48.443787: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 15:39:48.443796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 15:39:48.443812: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2/13 [===>..........................] - ETA: 23s - loss: 2655.2955 - acc: 0.281 3/13 [=====>........................] - ETA: 17s - loss: 1843.0947 - acc: 0.312 4/13 [========>.....................] - ETA: 14s - loss: 1588.9010 - acc: 0.296 5/13 [==========>...................] - ETA: 11s - loss: 1681.0050 - acc: 0.275 6/13 [============>.................] - ETA: 9s - loss: 1758.5785 - acc: 0.255213/13 [==============================] - 18s - loss: 1201.4869 - acc: 0.2524 - val_loss: 457.1766 - val_acc: 0.3333
Epoch 2/10
13/13 [==============================] - 12s - loss: 178.8184 - acc: 0.2480 - val_loss: 43.5585 - val_acc: 0.4533
Epoch 3/10
13/13 [==============================] - 11s - loss: 61.8117 - acc: 0.3123 - val_loss: 43.1232 - val_acc: 0.2267
Epoch 4/10
13/13 [==============================] - 12s - loss: 26.7388 - acc: 0.3195 - val_loss: 10.5261 - val_acc: 0.5067
Epoch 5/10
13/13 [==============================] - 12s - loss: 2.4628 - acc: 0.3840 - val_loss: 2.7851 - val_acc: 0.3200
Epoch 6/10
13/13 [==============================] - 12s - loss: 3.3117 - acc: 0.4209 - val_loss: 0.9634 - val_acc: 0.4267
Epoch 7/10
13/13 [==============================] - 11s - loss: 1.8041 - acc: 0.4422 - val_loss: 0.9356 - val_acc: 0.4667
Epoch 8/10
13/13 [==============================] - 11s - loss: 0.7606 - acc: 0.5822 - val_loss: 0.4951 - val_acc: 0.4933
Epoch 9/10
13/13 [==============================] - 12s - loss: 0.7251 - acc: 0.5798 - val_loss: 0.8177 - val_acc: 0.5333
Epoch 10/10
13/13 [==============================] - 12s - loss: 0.7555 - acc: 0.5894 - val_loss: 0.6068 - val_acc: 0.5467
Model saved successfully

7.

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 160, 160, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 158, 158, 16)      448       
_________________________________________________________________
flatten_1 (Flatten)          (None, 399424)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1597700   
=================================================================
Total params: 1,598,148
Trainable params: 1,598,148
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/10
2020-01-29 16:23:23.828962: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 16:23:23.829144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 16:23:23.829243: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 16:23:23.829342: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 22s - loss: 376.1562 - acc: 0.2578 - val_loss: 216.8326 - val_acc: 0.3646
Epoch 2/10
12/12 [==============================] - 18s - loss: 61.8717 - acc: 0.3830 - val_loss: 17.5659 - val_acc: 0.2429
Epoch 3/10
12/12 [==============================] - 17s - loss: 23.8590 - acc: 0.3987 - val_loss: 2.7328 - val_acc: 0.3714
Epoch 4/10
12/12 [==============================] - 17s - loss: 5.7656 - acc: 0.3495 - val_loss: 1.1850 - val_acc: 0.2429
Epoch 5/10
12/12 [==============================] - 17s - loss: 1.5216 - acc: 0.5791 - val_loss: 1.1521 - val_acc: 0.4143
Epoch 6/10
12/12 [==============================] - 17s - loss: 1.9813 - acc: 0.5203 - val_loss: 0.7410 - val_acc: 0.5571
Epoch 7/10
12/12 [==============================] - 17s - loss: 0.5112 - acc: 0.8554 - val_loss: 0.2136 - val_acc: 0.6429
Epoch 8/10
12/12 [==============================] - 17s - loss: 0.3733 - acc: 0.8788 - val_loss: 0.3542 - val_acc: 0.6429
Epoch 9/10
12/12 [==============================] - 17s - loss: 0.4181 - acc: 0.9113 - val_loss: 0.2950 - val_acc: 0.6857
Epoch 10/10
12/12 [==============================] - 17s - loss: 0.3427 - acc: 0.9426 - val_loss: 0.1670 - val_acc: 0.7143
Model saved successfully

8.

yer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 22, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 4, 4, 128)         8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 8196      
=================================================================
Total params: 41,044
Trainable params: 41,044
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/10
2020-01-29 17:05:35.420901: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:05:35.420945: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:05:35.420958: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:05:35.420969: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2104 - acc: 0.2969 - val_loss: 0.1997 - val_acc: 0.2812
Epoch 2/10
12/12 [==============================] - 5s - loss: 0.1924 - acc: 0.2587 - val_loss: 0.2001 - val_acc: 0.3143
Epoch 3/10
12/12 [==============================] - 5s - loss: 0.1855 - acc: 0.3484 - val_loss: 0.1914 - val_acc: 0.3000
Epoch 4/10
12/12 [==============================] - 5s - loss: 0.1791 - acc: 0.3771 - val_loss: 0.1876 - val_acc: 0.3286
Epoch 5/10
12/12 [==============================] - 5s - loss: 0.1712 - acc: 0.4660 - val_loss: 0.1831 - val_acc: 0.3714
Epoch 6/10
12/12 [==============================] - 5s - loss: 0.1675 - acc: 0.4975 - val_loss: 0.1807 - val_acc: 0.3714
Epoch 7/10
12/12 [==============================] - 5s - loss: 0.1658 - acc: 0.4932 - val_loss: 0.1725 - val_acc: 0.4286
Epoch 8/10
12/12 [==============================] - 5s - loss: 0.1585 - acc: 0.5395 - val_loss: 0.1621 - val_acc: 0.6000
Epoch 9/10
12/12 [==============================] - 5s - loss: 0.1493 - acc: 0.5969 - val_loss: 0.1573 - val_acc: 0.6286
Epoch 10/10
12/12 [==============================] - 5s - loss: 0.1495 - acc: 0.5499 - val_loss: 0.1509 - val_acc: 0.6000

9.

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 22, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 4, 4, 128)         8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 8196      
=================================================================
Total params: 41,044
Trainable params: 41,044
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/20
2020-01-29 17:07:22.807018: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:07:22.807053: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:07:22.807061: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:07:22.807068: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2025 - acc: 0.2708 - val_loss: 0.1947 - val_acc: 0.3229
Epoch 2/20
12/12 [==============================] - 5s - loss: 0.1894 - acc: 0.2656 - val_loss: 0.1959 - val_acc: 0.4000
Epoch 3/20
12/12 [==============================] - 5s - loss: 0.1823 - acc: 0.3581 - val_loss: 0.1853 - val_acc: 0.4571
Epoch 4/20
12/12 [==============================] - 5s - loss: 0.1785 - acc: 0.3910 - val_loss: 0.1799 - val_acc: 0.4143
Epoch 5/20
12/12 [==============================] - 5s - loss: 0.1756 - acc: 0.4278 - val_loss: 0.1738 - val_acc: 0.4286
Epoch 6/20
12/12 [==============================] - 5s - loss: 0.1658 - acc: 0.5288 - val_loss: 0.1669 - val_acc: 0.4571
Epoch 7/20
12/12 [==============================] - 5s - loss: 0.1568 - acc: 0.5466 - val_loss: 0.1623 - val_acc: 0.4429
Epoch 8/20
12/12 [==============================] - 5s - loss: 0.1478 - acc: 0.5937 - val_loss: 0.1557 - val_acc: 0.4286
Epoch 9/20
12/12 [==============================] - 5s - loss: 0.1430 - acc: 0.5961 - val_loss: 0.1463 - val_acc: 0.5571
Epoch 10/20
12/12 [==============================] - 5s - loss: 0.1334 - acc: 0.6753 - val_loss: 0.1335 - val_acc: 0.5857
Epoch 11/20
12/12 [==============================] - 5s - loss: 0.1214 - acc: 0.7024 - val_loss: 0.1184 - val_acc: 0.6143
Epoch 12/20
12/12 [==============================] - 5s - loss: 0.1130 - acc: 0.7415 - val_loss: 0.1119 - val_acc: 0.7143
Epoch 13/20
12/12 [==============================] - 6s - loss: 0.1048 - acc: 0.7294 - val_loss: 0.0993 - val_acc: 0.7714
Epoch 14/20
12/12 [==============================] - 6s - loss: 0.1003 - acc: 0.7656 - val_loss: 0.0861 - val_acc: 0.9143
Epoch 15/20
12/12 [==============================] - 5s - loss: 0.0898 - acc: 0.8304 - val_loss: 0.0802 - val_acc: 0.9000
Epoch 16/20
12/12 [==============================] - 5s - loss: 0.0879 - acc: 0.8380 - val_loss: 0.0787 - val_acc: 0.9000
Epoch 17/20
12/12 [==============================] - 5s - loss: 0.0785 - acc: 0.8703 - val_loss: 0.0693 - val_acc: 0.9000
Epoch 18/20
12/12 [==============================] - 5s - loss: 0.0724 - acc: 0.8921 - val_loss: 0.0605 - val_acc: 0.9429
Epoch 19/20
12/12 [==============================] - 5s - loss: 0.0680 - acc: 0.9009 - val_loss: 0.0599 - val_acc: 0.9429
Epoch 20/20
12/12 [==============================] - 5s - loss: 0.0637 - acc: 0.9016 - val_loss: 0.0589 - val_acc: 0.9286

9. ( best )

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 22, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 4, 4, 128)         8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 8196      
=================================================================
Total params: 41,044
Trainable params: 41,044
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/30
2020-01-29 17:10:10.211732: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:10:10.211768: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:10:10.211776: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-29 17:10:10.211782: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2034 - acc: 0.2708 - val_loss: 0.1961 - val_acc: 0.3542
Epoch 2/30
12/12 [==============================] - 5s - loss: 0.1828 - acc: 0.3223 - val_loss: 0.1883 - val_acc: 0.4000
Epoch 3/30
12/12 [==============================] - 5s - loss: 0.1714 - acc: 0.4589 - val_loss: 0.1771 - val_acc: 0.4714
Epoch 4/30
12/12 [==============================] - 5s - loss: 0.1682 - acc: 0.4539 - val_loss: 0.1710 - val_acc: 0.4714
Epoch 5/30
12/12 [==============================] - 5s - loss: 0.1556 - acc: 0.5454 - val_loss: 0.1617 - val_acc: 0.5286
Epoch 6/30
12/12 [==============================] - 5s - loss: 0.1435 - acc: 0.6061 - val_loss: 0.1519 - val_acc: 0.5857
Epoch 7/30
12/12 [==============================] - 5s - loss: 0.1424 - acc: 0.6063 - val_loss: 0.1412 - val_acc: 0.6000
Epoch 8/30
12/12 [==============================] - 5s - loss: 0.1291 - acc: 0.6429 - val_loss: 0.1332 - val_acc: 0.6429
Epoch 9/30
12/12 [==============================] - 5s - loss: 0.1229 - acc: 0.6753 - val_loss: 0.1230 - val_acc: 0.6714
Epoch 10/30
12/12 [==============================] - 5s - loss: 0.1155 - acc: 0.7335 - val_loss: 0.1161 - val_acc: 0.6857
Epoch 11/30
12/12 [==============================] - 5s - loss: 0.1042 - acc: 0.7683 - val_loss: 0.1100 - val_acc: 0.7714
Epoch 12/30
12/12 [==============================] - 5s - loss: 0.0992 - acc: 0.7683 - val_loss: 0.1017 - val_acc: 0.7857
Epoch 13/30
12/12 [==============================] - 5s - loss: 0.1005 - acc: 0.7631 - val_loss: 0.0949 - val_acc: 0.7429
Epoch 14/30
12/12 [==============================] - 5s - loss: 0.0925 - acc: 0.8125 - val_loss: 0.0929 - val_acc: 0.7286
Epoch 15/30
12/12 [==============================] - 5s - loss: 0.0792 - acc: 0.8414 - val_loss: 0.0801 - val_acc: 0.7714
Epoch 16/30
12/12 [==============================] - 5s - loss: 0.0753 - acc: 0.8712 - val_loss: 0.0757 - val_acc: 0.8571
Epoch 17/30
12/12 [==============================] - 5s - loss: 0.0730 - acc: 0.8729 - val_loss: 0.0813 - val_acc: 0.7714
Epoch 18/30
12/12 [==============================] - 5s - loss: 0.0693 - acc: 0.8748 - val_loss: 0.0704 - val_acc: 0.8286
Epoch 19/30
12/12 [==============================] - 5s - loss: 0.0622 - acc: 0.9243 - val_loss: 0.0619 - val_acc: 0.9000
Epoch 20/30
12/12 [==============================] - 5s - loss: 0.0576 - acc: 0.9348 - val_loss: 0.0631 - val_acc: 0.8571
Epoch 21/30
12/12 [==============================] - 5s - loss: 0.0550 - acc: 0.9364 - val_loss: 0.0641 - val_acc: 0.9286
Epoch 22/30
12/12 [==============================] - 5s - loss: 0.0572 - acc: 0.9113 - val_loss: 0.0605 - val_acc: 0.9286
Epoch 23/30
12/12 [==============================] - 5s - loss: 0.0476 - acc: 0.9452 - val_loss: 0.0504 - val_acc: 0.9286
Epoch 24/30
12/12 [==============================] - 5s - loss: 0.0448 - acc: 0.9556 - val_loss: 0.0449 - val_acc: 0.9429
Epoch 25/30
12/12 [==============================] - 5s - loss: 0.0400 - acc: 0.9573 - val_loss: 0.0476 - val_acc: 0.9143
Epoch 26/30
12/12 [==============================] - 5s - loss: 0.0411 - acc: 0.9661 - val_loss: 0.0433 - val_acc: 0.9571
Epoch 27/30
12/12 [==============================] - 5s - loss: 0.0382 - acc: 0.9531 - val_loss: 0.0369 - val_acc: 0.9714
Epoch 28/30
12/12 [==============================] - 5s - loss: 0.0351 - acc: 0.9661 - val_loss: 0.0368 - val_acc: 0.9571
Epoch 29/30
12/12 [==============================] - 5s - loss: 0.0355 - acc: 0.9713 - val_loss: 0.0337 - val_acc: 0.9857
Epoch 30/30
12/12 [==============================] - 5s - loss: 0.0322 - acc: 0.9791 - val_loss: 0.0337 - val_acc: 0.9857
Model saved successfully


10,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 16)        1168      
_________________________________________________________________
dropout_1 (Dropout)          (None, 45, 45, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 32400)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 129604    
=================================================================
Total params: 130,996
Trainable params: 130,996
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/30
2020-01-31 00:12:48.642904: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:12:48.642935: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:12:48.642943: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:12:48.642969: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 10s - loss: 1.0552 - acc: 0.3047 - val_loss: 0.4612 - val_acc: 0.3646
Epoch 2/30
12/12 [==============================] - 5s - loss: 0.2563 - acc: 0.4475 - val_loss: 0.1760 - val_acc: 0.5429
Epoch 3/30
12/12 [==============================] - 5s - loss: 0.1774 - acc: 0.4392 - val_loss: 0.1699 - val_acc: 0.4000
Epoch 4/30
12/12 [==============================] - 5s - loss: 0.1484 - acc: 0.6251 - val_loss: 0.1383 - val_acc: 0.6429
Epoch 5/30
12/12 [==============================] - 5s - loss: 0.0982 - acc: 0.8665 - val_loss: 0.1268 - val_acc: 0.7000
Epoch 6/30
12/12 [==============================] - 6s - loss: 0.0663 - acc: 0.9277 - val_loss: 0.1165 - val_acc: 0.7143
Epoch 7/30
12/12 [==============================] - 6s - loss: 0.0476 - acc: 0.9381 - val_loss: 0.1116 - val_acc: 0.7143
Epoch 8/30
12/12 [==============================] - 5s - loss: 0.0368 - acc: 0.9512 - val_loss: 0.1076 - val_acc: 0.7000
Epoch 9/30
12/12 [==============================] - 6s - loss: 0.0258 - acc: 0.9720 - val_loss: 0.1124 - val_acc: 0.7000
Epoch 10/30
12/12 [==============================] - 5s - loss: 0.0224 - acc: 0.9772 - val_loss: 0.1112 - val_acc: 0.7000
Epoch 11/30
12/12 [==============================] - 5s - loss: 0.0200 - acc: 0.9834 - val_loss: 0.1198 - val_acc: 0.7000
Epoch 12/30
12/12 [==============================] - 5s - loss: 0.0177 - acc: 0.9843 - val_loss: 0.1114 - val_acc: 0.7143
Epoch 13/30
12/12 [==============================] - 5s - loss: 0.0165 - acc: 0.9922 - val_loss: 0.1164 - val_acc: 0.7000
Epoch 14/30
12/12 [==============================] - 5s - loss: 0.0164 - acc: 0.9870 - val_loss: 0.1081 - val_acc: 0.7143
Epoch 15/30
12/12 [==============================] - 5s - loss: 0.0169 - acc: 0.9896 - val_loss: 0.1197 - val_acc: 0.6714
Epoch 16/30
12/12 [==============================] - 5s - loss: 0.0205 - acc: 0.9896 - val_loss: 0.1092 - val_acc: 0.6857
Epoch 17/30
12/12 [==============================] - 5s - loss: 0.0216 - acc: 0.9870 - val_loss: 0.1250 - val_acc: 0.7000
Epoch 18/30
12/12 [==============================] - 5s - loss: 0.0197 - acc: 0.9922 - val_loss: 0.1076 - val_acc: 0.7286
Epoch 19/30
12/12 [==============================] - 5s - loss: 0.0133 - acc: 0.9974 - val_loss: 0.1138 - val_acc: 0.7143
Epoch 20/30
12/12 [==============================] - 5s - loss: 0.0127 - acc: 0.9948 - val_loss: 0.1144 - val_acc: 0.7286
Epoch 21/30
12/12 [==============================] - 5s - loss: 0.0123 - acc: 0.9948 - val_loss: 0.1098 - val_acc: 0.7286
Epoch 22/30
12/12 [==============================] - 5s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.1070 - val_acc: 0.7286
Epoch 23/30
12/12 [==============================] - 5s - loss: 0.0101 - acc: 0.9974 - val_loss: 0.1120 - val_acc: 0.7286
Epoch 24/30
12/12 [==============================] - 5s - loss: 0.0092 - acc: 0.9948 - val_loss: 0.1137 - val_acc: 0.7286
Epoch 25/30
12/12 [==============================] - 5s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1061 - val_acc: 0.7286
Epoch 26/30
12/12 [==============================] - 6s - loss: 0.0094 - acc: 0.9948 - val_loss: 0.1053 - val_acc: 0.7286
Epoch 27/30
12/12 [==============================] - 5s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.7286
Epoch 28/30
12/12 [==============================] - 6s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.7286
Epoch 29/30
12/12 [==============================] - 5s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.7286
Epoch 30/30
12/12 [==============================] - 5s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.7286
Model saved successfully

12,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 92, 92, 16)        1168      
_________________________________________________________________
dropout_1 (Dropout)          (None, 92, 92, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 135424)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 541700    
=================================================================
Total params: 543,092
Trainable params: 543,092
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/30
2020-01-31 00:16:02.148450: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:16:02.148498: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:16:02.148513: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:16:02.148525: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 10s - loss: 14.8683 - acc: 0.2891 - val_loss: 4.8438 - val_acc: 0.3438
Epoch 2/30
12/12 [==============================] - 8s - loss: 2.3250 - acc: 0.4022 - val_loss: 0.2328 - val_acc: 0.2571
Epoch 3/30
12/12 [==============================] - 8s - loss: 0.3130 - acc: 0.2668 - val_loss: 0.3144 - val_acc: 0.2571
Epoch 4/30
12/12 [==============================] - 8s - loss: 0.2535 - acc: 0.3668 - val_loss: 0.2067 - val_acc: 0.2857
Epoch 5/30
12/12 [==============================] - 8s - loss: 0.1749 - acc: 0.4975 - val_loss: 0.1735 - val_acc: 0.5286
Epoch 6/30
12/12 [==============================] - 8s - loss: 0.1464 - acc: 0.6725 - val_loss: 0.1612 - val_acc: 0.6286
Epoch 7/30
12/12 [==============================] - 7s - loss: 0.1302 - acc: 0.8319 - val_loss: 0.1542 - val_acc: 0.6714
Epoch 8/30
12/12 [==============================] - 7s - loss: 0.1183 - acc: 0.8807 - val_loss: 0.1464 - val_acc: 0.7571
Epoch 9/30
12/12 [==============================] - 7s - loss: 0.1047 - acc: 0.9025 - val_loss: 0.1307 - val_acc: 0.7571
Epoch 10/30
12/12 [==============================] - 7s - loss: 0.0818 - acc: 0.9025 - val_loss: 0.1059 - val_acc: 0.7714
Epoch 11/30
12/12 [==============================] - 7s - loss: 0.0526 - acc: 0.9417 - val_loss: 0.0915 - val_acc: 0.7714
Epoch 12/30
12/12 [==============================] - 7s - loss: 0.0376 - acc: 0.9485 - val_loss: 0.0843 - val_acc: 0.8143
Epoch 13/30
12/12 [==============================] - 7s - loss: 0.0267 - acc: 0.9573 - val_loss: 0.0786 - val_acc: 0.7857
Epoch 14/30
12/12 [==============================] - 7s - loss: 0.0212 - acc: 0.9688 - val_loss: 0.0778 - val_acc: 0.8000
Epoch 15/30
12/12 [==============================] - 8s - loss: 0.0177 - acc: 0.9782 - val_loss: 0.0786 - val_acc: 0.7857
Epoch 16/30
12/12 [==============================] - 7s - loss: 0.0172 - acc: 0.9817 - val_loss: 0.0783 - val_acc: 0.7857
Epoch 17/30
12/12 [==============================] - 8s - loss: 0.0163 - acc: 0.9870 - val_loss: 0.0767 - val_acc: 0.8000
Epoch 18/30
12/12 [==============================] - 8s - loss: 0.0173 - acc: 0.9870 - val_loss: 0.0838 - val_acc: 0.7857
Epoch 19/30
12/12 [==============================] - 8s - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0784 - val_acc: 0.8000
Epoch 20/30
12/12 [==============================] - 8s - loss: 0.0132 - acc: 0.9922 - val_loss: 0.0747 - val_acc: 0.7857
Epoch 21/30
12/12 [==============================] - 8s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0789 - val_acc: 0.7857
Epoch 22/30
12/12 [==============================] - 8s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0771 - val_acc: 0.8000
Epoch 23/30
12/12 [==============================] - 8s - loss: 0.0100 - acc: 0.9922 - val_loss: 0.0754 - val_acc: 0.8286
Epoch 24/30
12/12 [==============================] - 8s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0771 - val_acc: 0.8143
Epoch 25/30
12/12 [==============================] - 8s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0753 - val_acc: 0.8143
Epoch 26/30
12/12 [==============================] - 8s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0751 - val_acc: 0.8286
Epoch 27/30
12/12 [==============================] - 8s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0768 - val_acc: 0.8286
Epoch 28/30
12/12 [==============================] - 8s - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0758 - val_acc: 0.8000
Epoch 29/30
12/12 [==============================] - 8s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.8143
Epoch 30/30
12/12 [==============================] - 8s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 0.8143
Model saved successfully
 
13,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 92, 92, 16)        1168      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 90, 90, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 259200)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1036804   
=================================================================
Total params: 1,042,836
Trainable params: 1,042,836
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/30
2020-01-31 00:21:51.239171: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:21:51.239206: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:21:51.239214: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-01-31 00:21:51.239222: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 15s - loss: 16.0873 - acc: 0.2943 - val_loss: 0.4182 - val_acc: 0.3438
Epoch 2/30
12/12 [==============================] - 12s - loss: 0.3628 - acc: 0.4786 - val_loss: 0.2160 - val_acc: 0.4286
Epoch 3/30
12/12 [==============================] - 13s - loss: 0.2049 - acc: 0.7901 - val_loss: 0.1901 - val_acc: 0.4857
Epoch 4/30
12/12 [==============================] - 12s - loss: 0.1658 - acc: 0.7109 - val_loss: 0.1969 - val_acc: 0.3429
Epoch 5/30
12/12 [==============================] - 13s - loss: 0.1229 - acc: 0.7877 - val_loss: 0.1426 - val_acc: 0.6286
Epoch 6/30
12/12 [==============================] - 13s - loss: 0.0726 - acc: 0.9208 - val_loss: 0.1295 - val_acc: 0.6286
Epoch 7/30
12/12 [==============================] - 13s - loss: 0.0438 - acc: 0.9583 - val_loss: 0.1207 - val_acc: 0.6714
Epoch 8/30
12/12 [==============================] - 12s - loss: 0.0328 - acc: 0.9739 - val_loss: 0.1098 - val_acc: 0.7000
Epoch 9/30
12/12 [==============================] - 12s - loss: 0.0312 - acc: 0.9817 - val_loss: 0.1130 - val_acc: 0.6857
Epoch 10/30
12/12 [==============================] - 12s - loss: 0.0280 - acc: 0.9765 - val_loss: 0.1080 - val_acc: 0.7000
Epoch 11/30
12/12 [==============================] - 13s - loss: 0.0248 - acc: 0.9922 - val_loss: 0.1079 - val_acc: 0.7143
Epoch 12/30
12/12 [==============================] - 13s - loss: 0.0250 - acc: 0.9896 - val_loss: 0.1033 - val_acc: 0.6857
Epoch 13/30
12/12 [==============================] - 12s - loss: 0.0194 - acc: 0.9896 - val_loss: 0.1008 - val_acc: 0.6857
Epoch 14/30
12/12 [==============================] - 12s - loss: 0.0142 - acc: 0.9896 - val_loss: 0.1037 - val_acc: 0.7000
Epoch 15/30
12/12 [==============================] - 12s - loss: 0.0098 - acc: 0.9948 - val_loss: 0.1036 - val_acc: 0.7143
Epoch 16/30
12/12 [==============================] - 12s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.6571
Epoch 17/30
12/12 [==============================] - 12s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.6429
Epoch 18/30
12/12 [==============================] - 12s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.6000
Epoch 19/30
12/12 [==============================] - 12s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.6286
Epoch 20/30
12/12 [==============================] - 12s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.6143
Epoch 21/30
12/12 [==============================] - 14s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.6143
Epoch 22/30
12/12 [==============================] - 13s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.6571
Epoch 23/30
12/12 [==============================] - 13s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.6875
Epoch 24/30
12/12 [==============================] - 12s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.6571
Epoch 25/30
12/12 [==============================] - 12s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.6857
Epoch 26/30
12/12 [==============================] - 12s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.6857
Epoch 27/30
12/12 [==============================] - 13s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.6286
Epoch 28/30
12/12 [==============================] - 13s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.6429
Epoch 29/30
12/12 [==============================] - 14s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.6979
Epoch 30/30
12/12 [==============================] - 13s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 0.6571
Model saved successfully


14,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 4)         112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 92, 92, 8)         296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 90, 90, 16)        1168      
_________________________________________________________________
flatten_1 (Flatten)          (None, 129600)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 518404    
=================================================================
Total params: 519,980
Trainable params: 519,980
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 17:23:32.476450: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 17:23:32.476481: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 17:23:32.476490: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 17:23:32.476497: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 13s - loss: 2.7281 - acc: 0.2891 - val_loss: 0.7165 - val_acc: 0.3125
Epoch 2/15
12/12 [==============================] - 9s - loss: 0.2534 - acc: 0.5476 - val_loss: 0.1916 - val_acc: 0.4571
Epoch 3/15
12/12 [==============================] - 8s - loss: 0.1599 - acc: 0.7150 - val_loss: 0.1577 - val_acc: 0.6429
Epoch 4/15
12/12 [==============================] - 8s - loss: 0.1308 - acc: 0.8285 - val_loss: 0.1389 - val_acc: 0.7000
Epoch 5/15
12/12 [==============================] - 8s - loss: 0.1013 - acc: 0.8869 - val_loss: 0.1239 - val_acc: 0.6857
Epoch 6/15
12/12 [==============================] - 8s - loss: 0.0758 - acc: 0.9208 - val_loss: 0.1084 - val_acc: 0.7286
Epoch 7/15
12/12 [==============================] - 10s - loss: 0.0569 - acc: 0.9391 - val_loss: 0.0989 - val_acc: 0.7286
Epoch 8/15
12/12 [==============================] - 10s - loss: 0.0431 - acc: 0.9469 - val_loss: 0.0913 - val_acc: 0.7429
Epoch 9/15
12/12 [==============================] - 10s - loss: 0.0306 - acc: 0.9625 - val_loss: 0.0867 - val_acc: 0.7571
Epoch 10/15
12/12 [==============================] - 8s - loss: 0.0242 - acc: 0.9730 - val_loss: 0.0841 - val_acc: 0.7857
Epoch 11/15
12/12 [==============================] - 8s - loss: 0.0186 - acc: 0.9808 - val_loss: 0.0834 - val_acc: 0.7857
Epoch 12/15
12/12 [==============================] - 8s - loss: 0.0147 - acc: 0.9808 - val_loss: 0.0851 - val_acc: 0.7571
Epoch 13/15
12/12 [==============================] - 8s - loss: 0.0121 - acc: 0.9886 - val_loss: 0.0855 - val_acc: 0.7571
Epoch 14/15
12/12 [==============================] - 8s - loss: 0.0101 - acc: 0.9922 - val_loss: 0.0828 - val_acc: 0.8000
Epoch 15/15
12/12 [==============================] - 10s - loss: 0.0089 - acc: 0.9912 - val_loss: 0.0813 - val_acc: 0.7857
Model saved successfully

15,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 400, 300, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 400, 300, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 398, 298, 4)       112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 396, 296, 8)       296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 394, 294, 16)      1168      
_________________________________________________________________
flatten_1 (Flatten)          (None, 1853376)           0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 7413508   
=================================================================
Total params: 7,415,084
Trainable params: 7,415,084
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 18:26:06.740534: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:26:06.740573: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:26:06.740582: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:26:06.740593: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2/12 [====>.........................] - ETA: 79s - loss: 1429.9024 - acc: 0.234 3/12 [======>.......................] - ETA: 63s - loss: 990.8256 - acc: 0.250012/12 [==============================] - 78s - loss: 478.7610 - acc: 0.2839 - val_loss: 4.1362 - val_acc: 0.3542
Epoch 2/15
12/12 [==============================] - 69s - loss: 23.1815 - acc: 0.3413 - val_loss: 6.4306 - val_acc: 0.3143
Epoch 3/15
12/12 [==============================] - 69s - loss: 2.1148 - acc: 0.4783 - val_loss: 0.3147 - val_acc: 0.2714
Epoch 4/15
12/12 [==============================] - 70s - loss: 0.3200 - acc: 0.6535 - val_loss: 0.2784 - val_acc: 0.5571
Epoch 5/15
12/12 [==============================] - 73s - loss: 0.3148 - acc: 0.7980 - val_loss: 0.2747 - val_acc: 0.4896
Epoch 6/15
12/12 [==============================] - 68s - loss: 0.2866 - acc: 0.8798 - val_loss: 0.2343 - val_acc: 0.6000
Epoch 7/15
12/12 [==============================] - 69s - loss: 0.2357 - acc: 0.8693 - val_loss: 0.2341 - val_acc: 0.4857
Epoch 8/15
12/12 [==============================] - 69s - loss: 0.2111 - acc: 0.8485 - val_loss: 0.2057 - val_acc: 0.6571
Epoch 9/15
12/12 [==============================] - 70s - loss: 0.1869 - acc: 0.9077 - val_loss: 0.2060 - val_acc: 0.6562
Epoch 10/15
12/12 [==============================] - 68s - loss: 0.1692 - acc: 0.9120 - val_loss: 0.1882 - val_acc: 0.6429
Epoch 11/15
12/12 [==============================] - 70s - loss: 0.1478 - acc: 0.9251 - val_loss: 0.1912 - val_acc: 0.6429
Epoch 12/15
12/12 [==============================] - 69s - loss: 0.1139 - acc: 0.9407 - val_loss: 0.1694 - val_acc: 0.7429
Epoch 13/15
12/12 [==============================] - 71s - loss: 0.1201 - acc: 0.9564 - val_loss: 0.1699 - val_acc: 0.6979
Epoch 14/15
12/12 [==============================] - 72s - loss: 0.1069 - acc: 0.9661 - val_loss: 0.1534 - val_acc: 0.6857
Epoch 15/15
12/12 [==============================] - 71s - loss: 0.0902 - acc: 0.9746 - val_loss: 0.1576 - val_acc: 0.6714
Model saved successfully

16,

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 200, 150, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 200, 150, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 198, 148, 4)       112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 196, 146, 8)       296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 194, 144, 16)      1168      
_________________________________________________________________
flatten_1 (Flatten)          (None, 446976)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1787908   
=================================================================
Total params: 1,789,484
Trainable params: 1,789,484
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 18:45:58.669127: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:45:58.669240: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:45:58.669293: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:45:58.669343: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 22s - loss: 30.9034 - acc: 0.3307 - val_loss: 2.9320 - val_acc: 0.2812
Epoch 2/15
12/12 [==============================] - 19s - loss: 2.5128 - acc: 0.7174 - val_loss: 0.8068 - val_acc: 0.5714
Epoch 3/15
12/12 [==============================] - 20s - loss: 0.4273 - acc: 0.8309 - val_loss: 0.2076 - val_acc: 0.7571
Epoch 4/15
12/12 [==============================] - 20s - loss: 0.1902 - acc: 0.8928 - val_loss: 0.2081 - val_acc: 0.6286
Epoch 5/15
12/12 [==============================] - 20s - loss: 0.1951 - acc: 0.9225 - val_loss: 0.1925 - val_acc: 0.7286
Epoch 6/15
12/12 [==============================] - 23s - loss: 0.1644 - acc: 0.9198 - val_loss: 0.1744 - val_acc: 0.6571
Epoch 7/15
12/12 [==============================] - 20s - loss: 0.1434 - acc: 0.9225 - val_loss: 0.1603 - val_acc: 0.7000
Epoch 8/15
12/12 [==============================] - 19s - loss: 0.1297 - acc: 0.9452 - val_loss: 0.1581 - val_acc: 0.7286
Epoch 9/15
12/12 [==============================] - 20s - loss: 0.1177 - acc: 0.9400 - val_loss: 0.1558 - val_acc: 0.6714
Epoch 10/15
12/12 [==============================] - 21s - loss: 0.1072 - acc: 0.9400 - val_loss: 0.1406 - val_acc: 0.7286
Epoch 11/15
12/12 [==============================] - 23s - loss: 0.0963 - acc: 0.9452 - val_loss: 0.1419 - val_acc: 0.7571
Epoch 12/15
12/12 [==============================] - 21s - loss: 0.0820 - acc: 0.9452 - val_loss: 0.1399 - val_acc: 0.7286
Epoch 13/15
12/12 [==============================] - 20s - loss: 0.0808 - acc: 0.9478 - val_loss: 0.1326 - val_acc: 0.7714
Epoch 14/15
12/12 [==============================] - 22s - loss: 0.0724 - acc: 0.9505 - val_loss: 0.1305 - val_acc: 0.7286
Epoch 15/15
12/12 [==============================] - 21s - loss: 0.0623 - acc: 0.9713 - val_loss: 0.1237 - val_acc: 0.7714
Model saved successfully

17,


_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 200, 150, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 200, 150, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 198, 148, 4)       112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 196, 146, 8)       296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 194, 144, 16)      1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 97, 72, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 111744)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 446980    
=================================================================
Total params: 448,556
Trainable params: 448,556
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 18:56:15.871964: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:56:15.872077: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:56:15.872130: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 18:56:15.872180: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 23s - loss: 3.4348 - acc: 0.3906 - val_loss: 0.9038 - val_acc: 0.6354
Epoch 2/15
12/12 [==============================] - 19s - loss: 0.5004 - acc: 0.6522 - val_loss: 0.1719 - val_acc: 0.6714
Epoch 3/15
12/12 [==============================] - 20s - loss: 0.1729 - acc: 0.8089 - val_loss: 0.1912 - val_acc: 0.7604
Epoch 4/15
12/12 [==============================] - 20s - loss: 0.1589 - acc: 0.8212 - val_loss: 0.1610 - val_acc: 0.6571
Epoch 5/15
12/12 [==============================] - 20s - loss: 0.1345 - acc: 0.8378 - val_loss: 0.1434 - val_acc: 0.7857
Epoch 6/15
12/12 [==============================] - 19s - loss: 0.1167 - acc: 0.8596 - val_loss: 0.1393 - val_acc: 0.7143
Epoch 7/15
12/12 [==============================] - 19s - loss: 0.1038 - acc: 0.9051 - val_loss: 0.1251 - val_acc: 0.7857
Epoch 8/15
12/12 [==============================] - 19s - loss: 0.0889 - acc: 0.9104 - val_loss: 0.1208 - val_acc: 0.7571
Epoch 9/15
12/12 [==============================] - 19s - loss: 0.0796 - acc: 0.9156 - val_loss: 0.1182 - val_acc: 0.7571
Epoch 10/15
12/12 [==============================] - 19s - loss: 0.0685 - acc: 0.9400 - val_loss: 0.1045 - val_acc: 0.8000
Epoch 11/15
12/12 [==============================] - 20s - loss: 0.0582 - acc: 0.9452 - val_loss: 0.1087 - val_acc: 0.7571
Epoch 12/15
12/12 [==============================] - 20s - loss: 0.0509 - acc: 0.9530 - val_loss: 0.0944 - val_acc: 0.8143
Epoch 13/15
12/12 [==============================] - 19s - loss: 0.0456 - acc: 0.9530 - val_loss: 0.0965 - val_acc: 0.8000
Epoch 14/15
12/12 [==============================] - 21s - loss: 0.0381 - acc: 0.9583 - val_loss: 0.0849 - val_acc: 0.8229
Epoch 15/15
12/12 [==============================] - 19s - loss: 0.0324 - acc: 0.9687 - val_loss: 0.0948 - val_acc: 0.7857
Model saved successfully


18,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 4)         112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 8)         296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 94, 69, 16)        1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 34, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25568)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 102276    
=================================================================
Total params: 103,852
Trainable params: 103,852
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:05:43.879295: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:05:43.879343: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:05:43.879357: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:05:43.879368: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 10s - loss: 0.3798 - acc: 0.3750 - val_loss: 0.2258 - val_acc: 0.5521
Epoch 2/15
12/12 [==============================] - 8s - loss: 0.1643 - acc: 0.6225 - val_loss: 0.1554 - val_acc: 0.7143
Epoch 3/15
12/12 [==============================] - 8s - loss: 0.1275 - acc: 0.7987 - val_loss: 0.1283 - val_acc: 0.7286
Epoch 4/15
12/12 [==============================] - 8s - loss: 0.0954 - acc: 0.8345 - val_loss: 0.1071 - val_acc: 0.7571
Epoch 5/15
12/12 [==============================] - 7s - loss: 0.0712 - acc: 0.8684 - val_loss: 0.0976 - val_acc: 0.7429
Epoch 6/15
12/12 [==============================] - 8s - loss: 0.0533 - acc: 0.9137 - val_loss: 0.0908 - val_acc: 0.7571
Epoch 7/15
12/12 [==============================] - 8s - loss: 0.0388 - acc: 0.9521 - val_loss: 0.0911 - val_acc: 0.7429
Epoch 8/15
12/12 [==============================] - 7s - loss: 0.0299 - acc: 0.9661 - val_loss: 0.0955 - val_acc: 0.7429
Epoch 9/15
12/12 [==============================] - 7s - loss: 0.0276 - acc: 0.9739 - val_loss: 0.0899 - val_acc: 0.7714
Epoch 10/15
12/12 [==============================] - 7s - loss: 0.0287 - acc: 0.9791 - val_loss: 0.1072 - val_acc: 0.8143
Epoch 11/15
12/12 [==============================] - 7s - loss: 0.0350 - acc: 0.9843 - val_loss: 0.0970 - val_acc: 0.7571
Epoch 12/15
12/12 [==============================] - 7s - loss: 0.0432 - acc: 0.9817 - val_loss: 0.1180 - val_acc: 0.7714
Epoch 13/15
12/12 [==============================] - 7s - loss: 0.0439 - acc: 0.9765 - val_loss: 0.0938 - val_acc: 0.7857
Epoch 14/15
12/12 [==============================] - 7s - loss: 0.0249 - acc: 0.9896 - val_loss: 0.0900 - val_acc: 0.7714
Epoch 15/15
12/12 [==============================] - 7s - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.7714
Model saved successfully


19,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 4)         112       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 36, 4)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 47, 34, 8)         296       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 45, 32, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 16, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 5632)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 22532     
=================================================================
Total params: 24,108
Trainable params: 24,108
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:09:33.182696: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:09:33.182733: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:09:33.182741: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:09:33.182849: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2111 - acc: 0.3047 - val_loss: 0.1785 - val_acc: 0.4792
Epoch 2/15
12/12 [==============================] - 5s - loss: 0.1473 - acc: 0.6095 - val_loss: 0.1659 - val_acc: 0.6143
Epoch 3/15
12/12 [==============================] - 5s - loss: 0.1184 - acc: 0.7562 - val_loss: 0.1432 - val_acc: 0.6143
Epoch 4/15
12/12 [==============================] - 5s - loss: 0.0935 - acc: 0.8084 - val_loss: 0.1317 - val_acc: 0.6286
Epoch 5/15
12/12 [==============================] - 5s - loss: 0.0786 - acc: 0.8240 - val_loss: 0.1195 - val_acc: 0.6857
Epoch 6/15
12/12 [==============================] - 5s - loss: 0.0679 - acc: 0.8651 - val_loss: 0.1150 - val_acc: 0.7286
Epoch 7/15
12/12 [==============================] - 5s - loss: 0.0577 - acc: 0.8904 - val_loss: 0.1156 - val_acc: 0.7714
Epoch 8/15
12/12 [==============================] - 5s - loss: 0.0485 - acc: 0.9374 - val_loss: 0.1224 - val_acc: 0.7429
Epoch 9/15
12/12 [==============================] - 5s - loss: 0.0426 - acc: 0.9426 - val_loss: 0.1186 - val_acc: 0.7429
Epoch 10/15
12/12 [==============================] - 5s - loss: 0.0414 - acc: 0.9530 - val_loss: 0.1144 - val_acc: 0.7143
Epoch 11/15
12/12 [==============================] - 5s - loss: 0.0393 - acc: 0.9609 - val_loss: 0.1298 - val_acc: 0.6857
Epoch 12/15
12/12 [==============================] - 5s - loss: 0.0428 - acc: 0.9530 - val_loss: 0.1077 - val_acc: 0.7000
Epoch 13/15
12/12 [==============================] - 5s - loss: 0.0436 - acc: 0.9635 - val_loss: 0.1187 - val_acc: 0.7286
Epoch 14/15
12/12 [==============================] - 5s - loss: 0.0389 - acc: 0.9661 - val_loss: 0.1047 - val_acc: 0.7571
Epoch 15/15
12/12 [==============================] - 5s - loss: 0.0300 - acc: 0.9817 - val_loss: 0.1059 - val_acc: 0.7429
Model saved successfully


20,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 35, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 26880)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 107524    
=================================================================
Total params: 108,916
Trainable params: 108,916
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:13:21.289563: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:13:21.289672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:13:21.289725: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:13:21.289774: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 8s - loss: 0.9460 - acc: 0.3411 - val_loss: 0.4480 - val_acc: 0.3229
Epoch 2/15
12/12 [==============================] - 6s - loss: 0.2452 - acc: 0.4648 - val_loss: 0.1834 - val_acc: 0.4714
Epoch 3/15
12/12 [==============================] - 6s - loss: 0.1669 - acc: 0.5165 - val_loss: 0.1584 - val_acc: 0.5429
Epoch 4/15
12/12 [==============================] - 6s - loss: 0.1277 - acc: 0.7553 - val_loss: 0.1360 - val_acc: 0.6143
Epoch 5/15
12/12 [==============================] - 7s - loss: 0.0884 - acc: 0.8615 - val_loss: 0.1075 - val_acc: 0.7857
Epoch 6/15
12/12 [==============================] - 6s - loss: 0.0656 - acc: 0.9113 - val_loss: 0.0940 - val_acc: 0.8000
Epoch 7/15
12/12 [==============================] - 6s - loss: 0.0490 - acc: 0.9374 - val_loss: 0.0928 - val_acc: 0.8286
Epoch 8/15
12/12 [==============================] - 6s - loss: 0.0393 - acc: 0.9530 - val_loss: 0.0948 - val_acc: 0.8000
Epoch 9/15
12/12 [==============================] - 6s - loss: 0.0312 - acc: 0.9687 - val_loss: 0.0894 - val_acc: 0.7714
Epoch 10/15
12/12 [==============================] - 6s - loss: 0.0261 - acc: 0.9739 - val_loss: 0.0820 - val_acc: 0.8000
Epoch 11/15
12/12 [==============================] - 6s - loss: 0.0230 - acc: 0.9739 - val_loss: 0.0782 - val_acc: 0.8143
Epoch 12/15
12/12 [==============================] - 6s - loss: 0.0211 - acc: 0.9817 - val_loss: 0.0754 - val_acc: 0.8000
Epoch 13/15
12/12 [==============================] - 7s - loss: 0.0205 - acc: 0.9765 - val_loss: 0.0891 - val_acc: 0.7714
Epoch 14/15
12/12 [==============================] - 7s - loss: 0.0219 - acc: 0.9844 - val_loss: 0.0870 - val_acc: 0.8000
Epoch 15/15
12/12 [==============================] - 7s - loss: 0.0181 - acc: 0.9870 - val_loss: 0.0799 - val_acc: 0.8429
Model saved successfully

21,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 35, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 46, 33, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 48576)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 194308    
=================================================================
Total params: 200,340
Trainable params: 200,340
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:18:08.780825: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:18:08.780915: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:18:08.780933: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:18:08.780946: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 9s - loss: 0.8873 - acc: 0.3099 - val_loss: 0.1868 - val_acc: 0.5000
Epoch 2/15
12/12 [==============================] - 8s - loss: 0.1866 - acc: 0.4738 - val_loss: 0.1779 - val_acc: 0.5714
Epoch 3/15
12/12 [==============================] - 7s - loss: 0.1651 - acc: 0.7109 - val_loss: 0.1473 - val_acc: 0.7429
Epoch 4/15
12/12 [==============================] - 7s - loss: 0.1162 - acc: 0.7387 - val_loss: 0.1041 - val_acc: 0.7429
Epoch 5/15
12/12 [==============================] - 7s - loss: 0.0732 - acc: 0.8442 - val_loss: 0.0814 - val_acc: 0.7857
Epoch 6/15
12/12 [==============================] - 7s - loss: 0.0472 - acc: 0.9286 - val_loss: 0.0736 - val_acc: 0.8571
Epoch 7/15
12/12 [==============================] - 7s - loss: 0.0368 - acc: 0.9573 - val_loss: 0.0703 - val_acc: 0.8714
Epoch 8/15
12/12 [==============================] - 7s - loss: 0.0334 - acc: 0.9599 - val_loss: 0.0637 - val_acc: 0.8714
Epoch 9/15
12/12 [==============================] - 7s - loss: 0.0277 - acc: 0.9739 - val_loss: 0.0638 - val_acc: 0.8714
Epoch 10/15
12/12 [==============================] - 8s - loss: 0.0267 - acc: 0.9739 - val_loss: 0.0697 - val_acc: 0.8857
Epoch 11/15
12/12 [==============================] - 7s - loss: 0.0219 - acc: 0.9791 - val_loss: 0.0910 - val_acc: 0.8286
Epoch 12/15
12/12 [==============================] - 7s - loss: 0.0223 - acc: 0.9791 - val_loss: 0.0841 - val_acc: 0.8143
Epoch 13/15
12/12 [==============================] - 7s - loss: 0.0266 - acc: 0.9782 - val_loss: 0.0650 - val_acc: 0.8857
Epoch 14/15
12/12 [==============================] - 7s - loss: 0.0253 - acc: 0.9870 - val_loss: 0.0636 - val_acc: 0.8857
Epoch 15/15
12/12 [==============================] - 7s - loss: 0.0214 - acc: 0.9896 - val_loss: 0.0688 - val_acc: 0.8714
Model saved successfully


22,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 35, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 46, 33, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 16, 32)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 11776)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 47108     
=================================================================
Total params: 53,140
Trainable params: 53,140
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:23:25.799923: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:23:25.799966: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:23:25.799975: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:23:25.799982: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 9s - loss: 0.2426 - acc: 0.3099 - val_loss: 0.1735 - val_acc: 0.4896
Epoch 2/15
12/12 [==============================] - 7s - loss: 0.1690 - acc: 0.5174 - val_loss: 0.1589 - val_acc: 0.5857
Epoch 3/15
12/12 [==============================] - 8s - loss: 0.1396 - acc: 0.6809 - val_loss: 0.1302 - val_acc: 0.6857
Epoch 4/15
12/12 [==============================] - 8s - loss: 0.1092 - acc: 0.7193 - val_loss: 0.0971 - val_acc: 0.8000
Epoch 5/15
12/12 [==============================] - 8s - loss: 0.0801 - acc: 0.8520 - val_loss: 0.0824 - val_acc: 0.8000
Epoch 6/15
12/12 [==============================] - 7s - loss: 0.0655 - acc: 0.8817 - val_loss: 0.0811 - val_acc: 0.8000
Epoch 7/15
12/12 [==============================] - 8s - loss: 0.0517 - acc: 0.9234 - val_loss: 0.0886 - val_acc: 0.7857
Epoch 8/15
12/12 [==============================] - 9s - loss: 0.0417 - acc: 0.9452 - val_loss: 0.0957 - val_acc: 0.8000
Epoch 9/15
12/12 [==============================] - 8s - loss: 0.0370 - acc: 0.9556 - val_loss: 0.0913 - val_acc: 0.8000
Epoch 10/15
12/12 [==============================] - 7s - loss: 0.0363 - acc: 0.9583 - val_loss: 0.0782 - val_acc: 0.8000
Epoch 11/15
12/12 [==============================] - 8s - loss: 0.0382 - acc: 0.9556 - val_loss: 0.0843 - val_acc: 0.8286
Epoch 12/15
12/12 [==============================] - 7s - loss: 0.0446 - acc: 0.9556 - val_loss: 0.0926 - val_acc: 0.8000
Epoch 13/15
12/12 [==============================] - 8s - loss: 0.0537 - acc: 0.9469 - val_loss: 0.0796 - val_acc: 0.8286
Epoch 14/15
12/12 [==============================] - 8s - loss: 0.0382 - acc: 0.9661 - val_loss: 0.0794 - val_acc: 0.7857
Epoch 15/15
12/12 [==============================] - 8s - loss: 0.0315 - acc: 0.9739 - val_loss: 0.0746 - val_acc: 0.8000
Model saved successfully

23,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 35, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 46, 33, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 16, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 21, 14, 64)        18496     
_________________________________________________________________
flatten_1 (Flatten)          (None, 18816)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 75268     
=================================================================
Total params: 99,796
Trainable params: 99,796
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:26:47.377040: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:26:47.377074: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:26:47.377083: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:26:47.377089: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 10s - loss: 0.2336 - acc: 0.2865 - val_loss: 0.1885 - val_acc: 0.5104
Epoch 2/15
12/12 [==============================] - 8s - loss: 0.1781 - acc: 0.5236 - val_loss: 0.1684 - val_acc: 0.4857
Epoch 3/15
12/12 [==============================] - 8s - loss: 0.1456 - acc: 0.6514 - val_loss: 0.1396 - val_acc: 0.6286
Epoch 4/15
12/12 [==============================] - 8s - loss: 0.1111 - acc: 0.7519 - val_loss: 0.1172 - val_acc: 0.6857
Epoch 5/15
12/12 [==============================] - 8s - loss: 0.0820 - acc: 0.8302 - val_loss: 0.0994 - val_acc: 0.7571
Epoch 6/15
12/12 [==============================] - 8s - loss: 0.0655 - acc: 0.8703 - val_loss: 0.0913 - val_acc: 0.7714
Epoch 7/15
12/12 [==============================] - 8s - loss: 0.0530 - acc: 0.8999 - val_loss: 0.0868 - val_acc: 0.7286
Epoch 8/15
12/12 [==============================] - 8s - loss: 0.0459 - acc: 0.9260 - val_loss: 0.0853 - val_acc: 0.8143
Epoch 9/15
12/12 [==============================] - 8s - loss: 0.0402 - acc: 0.9469 - val_loss: 0.0802 - val_acc: 0.8143
Epoch 10/15
12/12 [==============================] - 8s - loss: 0.0369 - acc: 0.9512 - val_loss: 0.0891 - val_acc: 0.7571
Epoch 11/15
12/12 [==============================] - 8s - loss: 0.0336 - acc: 0.9687 - val_loss: 0.0766 - val_acc: 0.8143
Epoch 12/15
12/12 [==============================] - 8s - loss: 0.0277 - acc: 0.9739 - val_loss: 0.0726 - val_acc: 0.8571
Epoch 13/15
12/12 [==============================] - 8s - loss: 0.0253 - acc: 0.9713 - val_loss: 0.0856 - val_acc: 0.8429
Epoch 14/15
12/12 [==============================] - 8s - loss: 0.0253 - acc: 0.9766 - val_loss: 0.0833 - val_acc: 0.8286
Epoch 15/15
12/12 [==============================] - 8s - loss: 0.0195 - acc: 0.9817 - val_loss: 0.0752 - val_acc: 0.8286
Model saved successfully

23,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 36, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 47, 34, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 17, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 21, 15, 32)        4640      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 7, 32)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2240)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 8964      
=================================================================
Total params: 14,996
Trainable params: 14,996
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:41:44.924283: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:41:44.924396: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:41:44.924518: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:41:44.924572: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2059 - acc: 0.3464 - val_loss: 0.1889 - val_acc: 0.3854
Epoch 2/15
12/12 [==============================] - 5s - loss: 0.1665 - acc: 0.5374 - val_loss: 0.1644 - val_acc: 0.4857
Epoch 3/15
12/12 [==============================] - 5s - loss: 0.1482 - acc: 0.6095 - val_loss: 0.1493 - val_acc: 0.5714
Epoch 4/15
12/12 [==============================] - 5s - loss: 0.1311 - acc: 0.6576 - val_loss: 0.1374 - val_acc: 0.5857
Epoch 5/15
12/12 [==============================] - 5s - loss: 0.1141 - acc: 0.6993 - val_loss: 0.1276 - val_acc: 0.6571
Epoch 6/15
12/12 [==============================] - 5s - loss: 0.1009 - acc: 0.7344 - val_loss: 0.1182 - val_acc: 0.7000
Epoch 7/15
12/12 [==============================] - 5s - loss: 0.0922 - acc: 0.7761 - val_loss: 0.1097 - val_acc: 0.7429
Epoch 8/15
12/12 [==============================] - 5s - loss: 0.0824 - acc: 0.8101 - val_loss: 0.1040 - val_acc: 0.7286
Epoch 9/15
12/12 [==============================] - 5s - loss: 0.0754 - acc: 0.8475 - val_loss: 0.1014 - val_acc: 0.7714
Epoch 10/15
12/12 [==============================] - 5s - loss: 0.0667 - acc: 0.8658 - val_loss: 0.0978 - val_acc: 0.7714
Epoch 11/15
12/12 [==============================] - 5s - loss: 0.0608 - acc: 0.8833 - val_loss: 0.0968 - val_acc: 0.7714
Epoch 12/15
12/12 [==============================] - 5s - loss: 0.0535 - acc: 0.9172 - val_loss: 0.0961 - val_acc: 0.7714
Epoch 13/15
12/12 [==============================] - 5s - loss: 0.0469 - acc: 0.9225 - val_loss: 0.0936 - val_acc: 0.7714
Epoch 14/15
12/12 [==============================] - 6s - loss: 0.0419 - acc: 0.9427 - val_loss: 0.0921 - val_acc: 0.7429
Epoch 15/15
12/12 [==============================] - 5s - loss: 0.0375 - acc: 0.9469 - val_loss: 0.0892 - val_acc: 0.7429
Model saved successfully


24,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 36, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 47, 34, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 17, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 21, 15, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 10080)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 40324     
=================================================================
Total params: 46,356
Trainable params: 46,356
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:47:52.648320: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:47:52.648435: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:47:52.648488: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:47:52.648602: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2213 - acc: 0.3203 - val_loss: 0.1695 - val_acc: 0.5208
Epoch 2/15
12/12 [==============================] - 5s - loss: 0.1608 - acc: 0.5744 - val_loss: 0.1533 - val_acc: 0.5857
Epoch 3/15
12/12 [==============================] - 5s - loss: 0.1311 - acc: 0.7280 - val_loss: 0.1236 - val_acc: 0.7000
Epoch 4/15
12/12 [==============================] - 5s - loss: 0.0933 - acc: 0.7925 - val_loss: 0.0999 - val_acc: 0.8286
Epoch 5/15
12/12 [==============================] - 5s - loss: 0.0688 - acc: 0.8772 - val_loss: 0.0898 - val_acc: 0.8143
Epoch 6/15
12/12 [==============================] - 5s - loss: 0.0528 - acc: 0.9198 - val_loss: 0.0831 - val_acc: 0.8429
Epoch 7/15
12/12 [==============================] - 5s - loss: 0.0423 - acc: 0.9485 - val_loss: 0.0783 - val_acc: 0.8143
Epoch 8/15
12/12 [==============================] - 5s - loss: 0.0374 - acc: 0.9642 - val_loss: 0.0883 - val_acc: 0.8000
Epoch 9/15
12/12 [==============================] - 5s - loss: 0.0390 - acc: 0.9668 - val_loss: 0.0810 - val_acc: 0.8143
Epoch 10/15
12/12 [==============================] - 5s - loss: 0.0319 - acc: 0.9756 - val_loss: 0.0756 - val_acc: 0.8714
Epoch 11/15
12/12 [==============================] - 5s - loss: 0.0208 - acc: 0.9896 - val_loss: 0.0762 - val_acc: 0.8286
Epoch 12/15
12/12 [==============================] - 5s - loss: 0.0178 - acc: 0.9843 - val_loss: 0.0698 - val_acc: 0.8571
Epoch 13/15
12/12 [==============================] - 5s - loss: 0.0154 - acc: 0.9922 - val_loss: 0.0747 - val_acc: 0.8571
Epoch 14/15
12/12 [==============================] - 5s - loss: 0.0141 - acc: 0.9896 - val_loss: 0.0761 - val_acc: 0.8429
Epoch 15/15
12/12 [==============================] - 5s - loss: 0.0153 - acc: 0.9896 - val_loss: 0.0747 - val_acc: 0.8857
Model saved successfully

25,

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 36, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 47, 34, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 17, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 23, 17, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 21, 15, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 10080)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 40324     
=================================================================
Total params: 46,356
Trainable params: 46,356
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 19:50:22.411231: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:50:22.411266: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:50:22.411275: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:50:22.411397: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2351 - acc: 0.2630 - val_loss: 0.1810 - val_acc: 0.3958
Epoch 2/15
12/12 [==============================] - 5s - loss: 0.1749 - acc: 0.4186 - val_loss: 0.1774 - val_acc: 0.4714
Epoch 3/15
12/12 [==============================] - 5s - loss: 0.1575 - acc: 0.5701 - val_loss: 0.1552 - val_acc: 0.5000
Epoch 4/15
12/12 [==============================] - 5s - loss: 0.1322 - acc: 0.6782 - val_loss: 0.1347 - val_acc: 0.5571
Epoch 5/15
12/12 [==============================] - 5s - loss: 0.1111 - acc: 0.7375 - val_loss: 0.1198 - val_acc: 0.7143
Epoch 6/15
12/12 [==============================] - 5s - loss: 0.0896 - acc: 0.8013 - val_loss: 0.1147 - val_acc: 0.7286
Epoch 7/15
12/12 [==============================] - 5s - loss: 0.0762 - acc: 0.8651 - val_loss: 0.1111 - val_acc: 0.7286
Epoch 8/15
12/12 [==============================] - 5s - loss: 0.0650 - acc: 0.8876 - val_loss: 0.1054 - val_acc: 0.7714
Epoch 9/15
12/12 [==============================] - 5s - loss: 0.0590 - acc: 0.9006 - val_loss: 0.0982 - val_acc: 0.7857
Epoch 10/15
12/12 [==============================] - 5s - loss: 0.0550 - acc: 0.9172 - val_loss: 0.1001 - val_acc: 0.8000
Epoch 11/15
12/12 [==============================] - 5s - loss: 0.0476 - acc: 0.9398 - val_loss: 0.0951 - val_acc: 0.7857
Epoch 12/15
12/12 [==============================] - 5s - loss: 0.0424 - acc: 0.9521 - val_loss: 0.0957 - val_acc: 0.8000
Epoch 13/15
12/12 [==============================] - 5s - loss: 0.0397 - acc: 0.9573 - val_loss: 0.0917 - val_acc: 0.8000
Epoch 14/15
12/12 [==============================] - 5s - loss: 0.0366 - acc: 0.9583 - val_loss: 0.0975 - val_acc: 0.8143
Epoch 15/15
12/12 [==============================] - 5s - loss: 0.0333 - acc: 0.9635 - val_loss: 0.0899 - val_acc: 0.8143
Model saved successfully

26,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 36, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 47, 34, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 17, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 23, 17, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 21, 15, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 10080)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 40324     
=================================================================
Total params: 46,356
Trainable params: 46,356
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/25
2020-02-02 19:53:15.950962: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:53:15.951111: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:53:15.951226: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 19:53:15.951307: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 7s - loss: 0.2248 - acc: 0.3125 - val_loss: 0.1758 - val_acc: 0.4583
Epoch 2/25
12/12 [==============================] - 5s - loss: 0.1711 - acc: 0.4537 - val_loss: 0.1727 - val_acc: 0.4286
Epoch 3/25
12/12 [==============================] - 5s - loss: 0.1503 - acc: 0.6085 - val_loss: 0.1538 - val_acc: 0.6000
Epoch 4/25
12/12 [==============================] - 5s - loss: 0.1203 - acc: 0.7038 - val_loss: 0.1450 - val_acc: 0.5714
Epoch 5/25
12/12 [==============================] - 5s - loss: 0.0986 - acc: 0.7840 - val_loss: 0.1410 - val_acc: 0.6143
Epoch 6/25
12/12 [==============================] - 5s - loss: 0.0834 - acc: 0.8354 - val_loss: 0.1315 - val_acc: 0.6571
Epoch 7/25
12/12 [==============================] - 5s - loss: 0.0695 - acc: 0.8729 - val_loss: 0.1320 - val_acc: 0.6857
Epoch 8/25
12/12 [==============================] - 5s - loss: 0.0679 - acc: 0.8885 - val_loss: 0.1288 - val_acc: 0.6857
Epoch 9/25
12/12 [==============================] - 5s - loss: 0.0570 - acc: 0.9208 - val_loss: 0.1266 - val_acc: 0.7143
Epoch 10/25
12/12 [==============================] - 5s - loss: 0.0467 - acc: 0.9452 - val_loss: 0.1192 - val_acc: 0.7000
Epoch 11/25
12/12 [==============================] - 5s - loss: 0.0452 - acc: 0.9364 - val_loss: 0.1191 - val_acc: 0.7429
Epoch 12/25
12/12 [==============================] - 5s - loss: 0.0402 - acc: 0.9452 - val_loss: 0.1187 - val_acc: 0.7286
Epoch 13/25
12/12 [==============================] - 5s - loss: 0.0372 - acc: 0.9556 - val_loss: 0.1181 - val_acc: 0.7000
Epoch 14/25
12/12 [==============================] - 6s - loss: 0.0352 - acc: 0.9714 - val_loss: 0.1111 - val_acc: 0.7714
Epoch 15/25
12/12 [==============================] - 5s - loss: 0.0323 - acc: 0.9609 - val_loss: 0.1137 - val_acc: 0.7571
Epoch 16/25
12/12 [==============================] - 5s - loss: 0.0303 - acc: 0.9765 - val_loss: 0.1194 - val_acc: 0.7286
Epoch 17/25
12/12 [==============================] - 5s - loss: 0.0309 - acc: 0.9843 - val_loss: 0.1137 - val_acc: 0.7571
Epoch 18/25
12/12 [==============================] - 5s - loss: 0.0274 - acc: 0.9739 - val_loss: 0.1152 - val_acc: 0.7857
Epoch 19/25
12/12 [==============================] - 5s - loss: 0.0296 - acc: 0.9791 - val_loss: 0.1113 - val_acc: 0.8286
Epoch 20/25
12/12 [==============================] - 5s - loss: 0.0265 - acc: 0.9791 - val_loss: 0.1156 - val_acc: 0.7429
Epoch 21/25
12/12 [==============================] - 5s - loss: 0.0255 - acc: 0.9896 - val_loss: 0.1107 - val_acc: 0.7429
Epoch 22/25
12/12 [==============================] - 5s - loss: 0.0230 - acc: 0.9791 - val_loss: 0.1095 - val_acc: 0.7143
Epoch 23/25
12/12 [==============================] - 5s - loss: 0.0211 - acc: 0.9896 - val_loss: 0.1069 - val_acc: 0.7429
Epoch 24/25
12/12 [==============================] - 5s - loss: 0.0233 - acc: 0.9948 - val_loss: 0.1045 - val_acc: 0.7714
Epoch 25/25
12/12 [==============================] - 5s - loss: 0.0249 - acc: 0.9948 - val_loss: 0.1063 - val_acc: 0.8143
Model saved successfully

27,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 94, 69, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 207552)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 830212    
=================================================================
Total params: 836,244
Trainable params: 836,244
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 20:05:54.451088: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:05:54.451200: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:05:54.451254: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:05:54.451304: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 14s - loss: 11.8849 - acc: 0.2656 - val_loss: 0.2608 - val_acc: 0.2396
Epoch 2/15
12/12 [==============================] - 11s - loss: 0.2116 - acc: 0.4129 - val_loss: 0.2072 - val_acc: 0.3429
Epoch 3/15
12/12 [==============================] - 12s - loss: 0.1941 - acc: 0.7247 - val_loss: 0.1851 - val_acc: 0.4571
Epoch 4/15
12/12 [==============================] - 11s - loss: 0.1462 - acc: 0.7743 - val_loss: 0.1603 - val_acc: 0.6143
Epoch 5/15
12/12 [==============================] - 11s - loss: 0.0908 - acc: 0.8648 - val_loss: 0.1227 - val_acc: 0.6857
Epoch 6/15
12/12 [==============================] - 11s - loss: 0.0483 - acc: 0.9362 - val_loss: 0.1020 - val_acc: 0.7571
Epoch 7/15
12/12 [==============================] - 11s - loss: 0.0355 - acc: 0.9713 - val_loss: 0.0977 - val_acc: 0.7571
Epoch 8/15
12/12 [==============================] - 11s - loss: 0.0264 - acc: 0.9843 - val_loss: 0.1122 - val_acc: 0.7286
Epoch 9/15
12/12 [==============================] - 11s - loss: 0.0301 - acc: 0.9843 - val_loss: 0.1013 - val_acc: 0.7857
Epoch 10/15
12/12 [==============================] - 11s - loss: 0.0324 - acc: 0.9817 - val_loss: 0.1130 - val_acc: 0.7429
Epoch 11/15
12/12 [==============================] - 11s - loss: 0.0329 - acc: 0.9817 - val_loss: 0.0979 - val_acc: 0.7714
Epoch 12/15
12/12 [==============================] - 11s - loss: 0.0209 - acc: 0.9870 - val_loss: 0.0978 - val_acc: 0.7571
Epoch 13/15
12/12 [==============================] - 11s - loss: 0.0141 - acc: 0.9843 - val_loss: 0.0937 - val_acc: 0.7571
Epoch 14/15
12/12 [==============================] - 11s - loss: 0.0105 - acc: 0.9896 - val_loss: 0.0922 - val_acc: 0.7857
Epoch 15/15
12/12 [==============================] - 11s - loss: 0.0099 - acc: 0.9922 - val_loss: 0.0908 - val_acc: 0.7857
Model saved successfully

28,

Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 100, 75, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 98, 73, 8)         224       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 96, 71, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 48, 35, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 46, 33, 32)        4640      
_________________________________________________________________
flatten_1 (Flatten)          (None, 48576)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 194308    
=================================================================
Total params: 200,340
Trainable params: 200,340
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/15
2020-02-02 20:15:12.186692: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:15:12.188049: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:15:12.189207: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-02 20:15:12.189895: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
12/12 [==============================] - 9s - loss: 0.9495 - acc: 0.2604 - val_loss: 0.1899 - val_acc: 0.4792
Epoch 2/15
12/12 [==============================] - 8s - loss: 0.1885 - acc: 0.5431 - val_loss: 0.1840 - val_acc: 0.5286
Epoch 3/15
12/12 [==============================] - 7s - loss: 0.1667 - acc: 0.5912 - val_loss: 0.1473 - val_acc: 0.5571
Epoch 4/15
12/12 [==============================] - 8s - loss: 0.1251 - acc: 0.6922 - val_loss: 0.1228 - val_acc: 0.7286
Epoch 5/15
12/12 [==============================] - 7s - loss: 0.0854 - acc: 0.8667 - val_loss: 0.1034 - val_acc: 0.7714
Epoch 6/15
12/12 [==============================] - 8s - loss: 0.0619 - acc: 0.8833 - val_loss: 0.0976 - val_acc: 0.8000
Epoch 7/15
12/12 [==============================] - 7s - loss: 0.0470 - acc: 0.9417 - val_loss: 0.1099 - val_acc: 0.7571
Epoch 8/15
12/12 [==============================] - 8s - loss: 0.0416 - acc: 0.9400 - val_loss: 0.0952 - val_acc: 0.8000
Epoch 9/15
12/12 [==============================] - 8s - loss: 0.0368 - acc: 0.9530 - val_loss: 0.0914 - val_acc: 0.8000
Epoch 10/15
12/12 [==============================] - 7s - loss: 0.0318 - acc: 0.9635 - val_loss: 0.0972 - val_acc: 0.7714
Epoch 11/15
12/12 [==============================] - 7s - loss: 0.0315 - acc: 0.9661 - val_loss: 0.0898 - val_acc: 0.7714
Epoch 12/15
12/12 [==============================] - 7s - loss: 0.0250 - acc: 0.9713 - val_loss: 0.1000 - val_acc: 0.7429
Epoch 13/15
12/12 [==============================] - 7s - loss: 0.0217 - acc: 0.9791 - val_loss: 0.0906 - val_acc: 0.7857
Epoch 14/15
12/12 [==============================] - 8s - loss: 0.0196 - acc: 0.9818 - val_loss: 0.0913 - val_acc: 0.8143
Epoch 15/15
12/12 [==============================] - 7s - loss: 0.0163 - acc: 0.9843 - val_loss: 0.0887 - val_acc: 0.8429

last.

Using TensorFlow backend.
----model data file is ready----
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 8)         224       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 8)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 16)        1168      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 22, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 4, 4, 128)         8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 8196      
=================================================================
Total params: 41,044
Trainable params: 41,044
Non-trainable params: 0
_________________________________________________________________
Training started
Epoch 1/20
2020-02-06 22:04:16.466625: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 22:04:16.466935: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 22:04:16.467130: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 22:04:16.467417: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
11/12 [==========================>...] - ETA: 0s - loss: 0.2045 - acc: 0.2557Epoch 00000: val_acc improved from -inf to 0.28125, saving model to best_weights.hdf5
12/12 [==============================] - 15s - loss: 0.2037 - acc: 0.2578 - val_loss: 0.2015 - val_acc: 0.2812
Epoch 2/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1860 - acc: 0.3192Epoch 00001: val_acc improved from 0.28125 to 0.45714, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1860 - acc: 0.3213 - val_loss: 0.1884 - val_acc: 0.4571
Epoch 3/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1753 - acc: 0.4163Epoch 00002: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.1747 - acc: 0.4181 - val_loss: 0.1846 - val_acc: 0.3571
Epoch 4/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1730 - acc: 0.4366Epoch 00003: val_acc improved from 0.45714 to 0.50000, saving model to best_weights.hdf5
12/12 [==============================] - 9s - loss: 0.1721 - acc: 0.4418 - val_loss: 0.1777 - val_acc: 0.5000
Epoch 5/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1653 - acc: 0.5077Epoch 00004: val_acc improved from 0.50000 to 0.52857, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1649 - acc: 0.5122 - val_loss: 0.1713 - val_acc: 0.5286
Epoch 6/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1551 - acc: 0.5434Epoch 00005: val_acc improved from 0.52857 to 0.55714, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1556 - acc: 0.5473 - val_loss: 0.1615 - val_acc: 0.5571
Epoch 7/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1463 - acc: 0.6041Epoch 00006: val_acc improved from 0.55714 to 0.60000, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1462 - acc: 0.6004 - val_loss: 0.1520 - val_acc: 0.6000
Epoch 8/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1417 - acc: 0.5814Epoch 00007: val_acc improved from 0.60000 to 0.62857, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1416 - acc: 0.5769 - val_loss: 0.1437 - val_acc: 0.6286
Epoch 9/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1332 - acc: 0.6178Epoch 00008: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.1318 - acc: 0.6263 - val_loss: 0.1333 - val_acc: 0.6286
Epoch 10/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1265 - acc: 0.6695Epoch 00009: val_acc improved from 0.62857 to 0.68571, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1269 - acc: 0.6682 - val_loss: 0.1270 - val_acc: 0.6857
Epoch 11/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1165 - acc: 0.7149Epoch 00010: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.1158 - acc: 0.7256 - val_loss: 0.1217 - val_acc: 0.6571
Epoch 12/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1152 - acc: 0.6882Epoch 00011: val_acc improved from 0.68571 to 0.71429, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1136 - acc: 0.7012 - val_loss: 0.1131 - val_acc: 0.7143
Epoch 13/20
11/12 [==========================>...] - ETA: 0s - loss: 0.1061 - acc: 0.7614Epoch 00012: val_acc did not improve
12/12 [==============================] - 7s - loss: 0.1047 - acc: 0.7595 - val_loss: 0.1137 - val_acc: 0.6286
Epoch 14/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0958 - acc: 0.7869Epoch 00013: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0975 - acc: 0.7786 - val_loss: 0.1035 - val_acc: 0.6714
Epoch 15/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0868 - acc: 0.8166Epoch 00014: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0880 - acc: 0.8110 - val_loss: 0.1020 - val_acc: 0.7000
Epoch 16/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0852 - acc: 0.8461Epoch 00015: val_acc improved from 0.71429 to 0.75714, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0830 - acc: 0.8537 - val_loss: 0.0869 - val_acc: 0.7571
Epoch 17/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0739 - acc: 0.8586Epoch 00016: val_acc improved from 0.75714 to 0.80000, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0742 - acc: 0.8572 - val_loss: 0.0806 - val_acc: 0.8000
Epoch 18/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0673 - acc: 0.8767Epoch 00017: val_acc improved from 0.80000 to 0.88571, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0665 - acc: 0.8817 - val_loss: 0.0643 - val_acc: 0.8857
Epoch 19/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0594 - acc: 0.9250Epoch 00018: val_acc improved from 0.88571 to 0.90000, saving model to best_weights.hdf5
12/12 [==============================] - 7s - loss: 0.0605 - acc: 0.9234 - val_loss: 0.0608 - val_acc: 0.9000
Epoch 20/20
11/12 [==========================>...] - ETA: 0s - loss: 0.0558 - acc: 0.9268Epoch 00019: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0554 - acc: 0.9277 - val_loss: 0.0600 - val_acc: 0.8571
weights saved successfully
Model saved successfully
(1, 600, 800, 3)
/usr/lib/python2.7/dist-packages/matplotlib/axes/_base.py:3045: UserWarning: Attempting to set identical bottom==top results
in singular transformations; automatically expanding.
bottom=-0.5, top=-0.5
  'bottom=%s, top=%s') % (bottom, top))




