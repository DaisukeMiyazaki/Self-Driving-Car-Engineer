Using TensorFlow backend.
----model data file is ready----
_________________________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 600, 800, 3)       0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 96, 96, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 94, 94, 16)        448       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 47, 47, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 47, 47, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 10, 10, 64)        0         
_________________________________________________________________
dense_1 (Dense)              (None, 10, 10, 128)       8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 10, 10, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12800)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 51204     
=================================================================
Total params: 83,108
Trainable params: 83,108
Non-trainable params: 0
_________________________________________________________________
None
Training started
Epoch 1/25
2020-02-06 23:52:59.891577: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 23:52:59.891625: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 23:52:59.891640: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-02-06 23:52:59.891652: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
11/12 [==========================>...] - ETA: 0s - loss: 0.2514 - acc: 0.2727Epoch 00000: val_acc improved from -inf to 0.26042, saving model to best_weights.hdf5
12/12 [==============================] - 11s - loss: 0.2483 - acc: 0.2760 - val_loss: 0.1935 - val_acc: 0.2604
Epoch 2/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1917 - acc: 0.3135Epoch 00001: val_acc improved from 0.26042 to 0.32857, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1905 - acc: 0.3239 - val_loss: 0.2016 - val_acc: 0.3286
Epoch 3/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1741 - acc: 0.4384Epoch 00002: val_acc improved from 0.32857 to 0.38571, saving model to best_weights.hdf5
12/12 [==============================] - 9s - loss: 0.1742 - acc: 0.4304 - val_loss: 0.1986 - val_acc: 0.3857
Epoch 4/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1683 - acc: 0.4622Epoch 00003: val_acc improved from 0.38571 to 0.45714, saving model to best_weights.hdf5
12/12 [==============================] - 9s - loss: 0.1674 - acc: 0.4731 - val_loss: 0.1886 - val_acc: 0.4571
Epoch 5/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1617 - acc: 0.4685Epoch 00004: val_acc improved from 0.45714 to 0.51429, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1614 - acc: 0.4764 - val_loss: 0.1808 - val_acc: 0.5143
Epoch 6/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1501 - acc: 0.5361Epoch 00005: val_acc improved from 0.51429 to 0.58571, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1482 - acc: 0.5513 - val_loss: 0.1676 - val_acc: 0.5857
Epoch 7/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1356 - acc: 0.6189Epoch 00006: val_acc improved from 0.58571 to 0.64286, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1350 - acc: 0.6246 - val_loss: 0.1464 - val_acc: 0.6429
Epoch 8/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.6843Epoch 00007: val_acc improved from 0.64286 to 0.68571, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1180 - acc: 0.6872 - val_loss: 0.1442 - val_acc: 0.6857
Epoch 9/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1125 - acc: 0.7638Epoch 00008: val_acc improved from 0.68571 to 0.72857, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.1120 - acc: 0.7629 - val_loss: 0.1311 - val_acc: 0.7286
Epoch 10/25
11/12 [==========================>...] - ETA: 0s - loss: 0.1010 - acc: 0.7689Epoch 00009: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.1020 - acc: 0.7648 - val_loss: 0.1323 - val_acc: 0.7000
Epoch 11/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0928 - acc: 0.8166Epoch 00010: val_acc improved from 0.72857 to 0.74286, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0912 - acc: 0.8240 - val_loss: 0.1221 - val_acc: 0.7429
Epoch 12/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0894 - acc: 0.8041Epoch 00011: val_acc improved from 0.74286 to 0.75714, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0892 - acc: 0.8101 - val_loss: 0.1164 - val_acc: 0.7571
Epoch 13/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0799 - acc: 0.8438Epoch 00012: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0792 - acc: 0.8459 - val_loss: 0.1167 - val_acc: 0.7000
Epoch 14/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0736 - acc: 0.8864Epoch 00013: val_acc improved from 0.75714 to 0.80000, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0732 - acc: 0.8880 - val_loss: 0.1035 - val_acc: 0.8000
Epoch 15/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0593 - acc: 0.9137Epoch 00014: val_acc improved from 0.80000 to 0.84286, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0600 - acc: 0.9130 - val_loss: 0.0967 - val_acc: 0.8429
Epoch 16/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0590 - acc: 0.9279Epoch 00015: val_acc did not improve
12/12 [==============================] - 7s - loss: 0.0573 - acc: 0.9286 - val_loss: 0.0979 - val_acc: 0.8143
Epoch 17/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0621 - acc: 0.9268Epoch 00016: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0619 - acc: 0.9225 - val_loss: 0.0923 - val_acc: 0.8286
Epoch 18/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0542 - acc: 0.9296Epoch 00017: val_acc improved from 0.84286 to 0.87143, saving model to best_weights.hdf5
12/12 [==============================] - 8s - loss: 0.0534 - acc: 0.9329 - val_loss: 0.0829 - val_acc: 0.8714
Epoch 19/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0494 - acc: 0.9506Epoch 00018: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0488 - acc: 0.9495 - val_loss: 0.0831 - val_acc: 0.8429
Epoch 20/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0492 - acc: 0.9449Epoch 00019: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0487 - acc: 0.9495 - val_loss: 0.0764 - val_acc: 0.8429
Epoch 21/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0432 - acc: 0.9648Epoch 00020: val_acc improved from 0.87143 to 0.88571, saving model to best_weights.hdf5
12/12 [==============================] - 7s - loss: 0.0435 - acc: 0.9678 - val_loss: 0.0735 - val_acc: 0.8857
Epoch 22/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0482 - acc: 0.9676Epoch 00021: val_acc did not improve
12/12 [==============================] - 9s - loss: 0.0478 - acc: 0.9704 - val_loss: 0.0795 - val_acc: 0.8857
Epoch 23/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0431 - acc: 0.9762Epoch 00022: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0435 - acc: 0.9756 - val_loss: 0.0720 - val_acc: 0.8857
Epoch 24/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0390 - acc: 0.9733Epoch 00023: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0397 - acc: 0.9756 - val_loss: 0.0685 - val_acc: 0.8714
Epoch 25/25
11/12 [==========================>...] - ETA: 0s - loss: 0.0397 - acc: 0.9864Epoch 00024: val_acc did not improve
12/12 [==============================] - 8s - loss: 0.0398 - acc: 0.9851 - val_loss: 0.0661 - val_acc: 0.8857
